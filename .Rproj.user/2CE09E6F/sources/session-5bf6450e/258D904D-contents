---
title: "Newark Flight Data"
author: "Malcolm Speight"
date: "2023-02-13"
output: html_document
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(lubridate)
library(modelr)
library(janitor)
library(car)
library(ROSE)
```

```{r, include=FALSE}
flights_data <- read_csv("data/flights.csv") %>% 
  janitor::clean_names()
airports_data <- read_csv("data/airports.csv") %>% 
  janitor::clean_names()
weather_data <- read_csv("data/weather.csv") %>% 
  janitor::clean_names()
plane_data <- read_csv("data/planes.csv") %>% 
  janitor::clean_names()
```


## Context

### BI and data-driven decision making

NEED TO POPULATE THIS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!



### Domain knowledge and the business context


I received a data set from Newark Liberty International Airport (IATA airport code "EWR") which captures departing flights from EWR in the year 2017. 

The airport is located 10 miles south-west of New York City (NYC) and is one of three international airports serving NYC, along with La Guardia and JFK airports. Of the three, EWR is the second busiest. In 2017 over 43 million passengers traveled through the airport compared to 55 million at JFK and 30 million at La Guardia.

In addition to 2017 flight departures, datasets relating to airports, airlines, planes and weather records for all three NYC airports were provided to me.  

Newark Airport believe poor weather conditions are causing too many delays to departing flights. They wish to ascertain if this assumption is correct and if it is, they are willing improve facilities at the airport to reduce the impact of weather related delays if possible. 

As such I have been asked by Newark Airport to use the data provided to answer the following business questions:

- what effect does the weather have on flight departure delays?
- how serious weather related delays are?
- what types of weather impacts delays the most?
- what other factors impact delays?
- rank the importance of delay factors.
- compare delays at Newark Airport to the other NYC airports.


## Data


### Internal and external data sources

**Internal data**
Five data sets were provided to me by Newark Airport:

*flights* - contained various data points all relating to flights departing the three NYC international airports during 2017. Examples of data points include departure date, departure time, arrival time, departure delay, flight number, distance between origin and destination airports. 

*airports* - details of over 1,300 airports in the USA including their IATA airport code, latitude and longitude. 

*airlines* - the carrier name and code of 12 airlines

*planes* - details of over 3,500 aeroplanes listing amongst other things their tail number (unique identifier), year of manufacture and seat numbers (capacity)

*weather* - weather data for all three NYC international airports in 2017. 


**External data**
Despite an extensive internet search I could not find free access to hourly weather data for Newark Airport and so was unable to supplement the data set provided to me. 


### Types of data

The datasets provided contain date-time, numerical and character data types.

The date-time data type `<dttm>` contains a date plus a time. These are used for the `time_hour` variables in the data set which records the date and hour of flight departures and weather recordings. 

All of the numeric variables are of type double (or `<dbl>`) which is the default treatment for numbers and is able to store numbers as decimals. This is appropriate for the longitude, latitude and wind speed variables which are continuous in nature but isn't really required for any of the other numerical variables (e.g. the year a plane was manufactured or how many engines it has) which could have been classed as `integer`.

Character variables `<chr>` capture letters, words and can even contain whole sentences. As an example, they were used in this dataset to capture amongst other things, the airline name (`airline`) and tail number (`tailnum`) of the departing plane. 

Logical variables (`<lgl>`) are a categorical variable used to represent boolean values in R. They can only take the value of 'TRUE' or 'FALSE'. 

Factor variables (`<fct>`) are also a form of categorical variable. They can capture data which cannot be ranked or ordered (nominal data) such gender. They can also be used to capture values which have a natural order to them such as 'clothing size' or 'film rating'.  

I used both logical and factor variables in my analysis to capture boolean values. 


### Data formats

All the data sets used in this analysis were provided by Newark Airport. Each file was in a `csv` format.


### Data quality and bias


## Ethics

### Ethical issues in data sourcing and extraction


### Ethical implications of business requirements


## Analysis


*Logistic regression*

Attempting to define a linear regression model for delays and weather data proved inconclusive. Linear regression is suited to addressing dependent variables that have continuous values. However, the delay associated with a plane departing an airport can be seen not to have a linear relationship to a series of variables as their impact on delay is changeable and dependent on many other factors or a combination of factors. In such circumstances it is clearly better to categorise our dependent variable, to begin with at least, as having two values: `delay` or `no-delay`.  

**Weather related delays**

_Flight data_
Flights leaving Newark Airport can be extracted from the main flights dataset (`flights_data`) after joining with `airports_data` and filtering on Newark Airport. 

```{r}
# capture only newark airport flights
newark_flights <- inner_join(flights_data, airports_data, by = c("origin" = "faa")) %>% 
  filter(name == "Newark Liberty International Airport") 
```

The `newark_flights` data contains 26 variables with 115,968 observations. 

```{r}
glimpse(newark_flights)
```

Some of the data is superfluous and is repeated for each entry so we can remove details of Newark Airport such as the `name` and `latitude` and `longitude` and the like (`alt`, `tz`, `dst`, `tzone`, `origin`). 

Instead of the day number represented by `day`, it might be beneficial to include a variable for the the day name to capture the days of the week. This can be extracted from `time_hour`.

As such the current `day` variable should be removed as should `year` as each observation is for the same year.

The `hour` variable captures sufficient information about the scheduled departure time so `dep_time` can be removed as can `sched_dep_time`. The `minute` variable is also superfluous. 

The arrival times, both scheduled and actual, and arrival delay are not predictor variables as they are a consequence of any delay on departure so can be removed. 

The flight number (`flight`) also does not have a predictive quality. It doesn't describe the departure or the circumstances at the time of departure, so should be removed. 

```{r}
newark_flights <- newark_flights %>% 
  select(-c(name, lat, lon, alt, tz, dst, tzone, origin)) %>% 
  select(-c(year, day, minute)) %>% 
  select(-c(dep_time, sched_dep_time, arr_time, sched_arr_time, arr_delay)) %>% 
  select(-flight) %>% 
  mutate(day = wday(time_hour, label = TRUE)) # new day name variable
```

We reduce the number of variables from 26 to 10.

```{r}
glimpse(newark_flights)
```

There are a number of missing values across the dataset. 

```{r}
colSums(is.na(newark_flights))
```

We start by looking at the summary statistics. 

```{r}
newark_flights %>% 
  select(dep_delay, tailnum, air_time) %>% 
  summary()
```
The amount of time the flight spends in the air (`air_time`) has a considerable number of missing values. These could be considered erroneous but more likely they indicate that the flight has been cancelled. A new variable (`cancelled`) could be added to capture this information then the `NA` values within `air_time` can be converted to a zero value. This would allow another regression model to be constructed to predict cancellations. For the moment, we will remove the `NA` values within `air_time`.

```{r}
# remove NAs from air_time
newark_flights_clean <- newark_flights %>% 
  drop_na(air_time)
```

For `dep_delay` we can use mean imputation to resolve the missing values. 

```{r}
newark_flights_clean <- newark_flights_clean %>% 
  mutate(dep_delay = coalesce(dep_delay, mean(dep_delay, na.rm = TRUE)))
```

The summary statistics are relatively unchanged for `dep_delay` 

```{r}
newark_flights_clean %>% 
  select(dep_delay) %>% 
  summary()
```
For the remaining `tailnum` variable, I'll replace missing values with "ABCXYZ".

```{r}
newark_flights_clean <- newark_flights_clean %>% 
  mutate(tailnum = ifelse(is.na(tailnum), "ABCXYZ", tailnum))
```

There should now be no missing values within the newark_flights_clean dataset. 

```{r}
colSums(is.na(newark_flights_clean))
```


The number of observations has reduced by the number of `NAs` or cancelled flights (3,266) captured within `air_time`. We now have 112,702 observations.

```{r}
dim(newark_flights_clean)
```


_Dependent variable_
There is currently no dependent variable (class) in the dataset so we should add one. Newark Airport are interested in departure delays. Although the US aviation authority (The FAA) state that flights departing with less than a 15 minute delay are deemed to be 'on time', we will classify all flights with a departure delay of greater than 0 as being delayed. Once added we can remove the `dep_delay` variable.

```{r}
# add dependent variable
newark_flights_clean <- newark_flights_clean %>% 
  mutate(delayed = ifelse(dep_delay > 0, TRUE, FALSE), .after = dep_delay) %>% 
  select(-dep_delay)
```


_Weather data_
Weather relating to Newark Airport can be extracted from the larger `weather_data` population by filtering on "EWR", the IATA code for Newark Airport.

```{r}
# capture only newark weather
newark_weather <- weather_data %>% 
  filter(origin == "EWR")
```

The newark weather data contains 15 variables with 8,735 observations. 

```{r}
glimpse(newark_weather)
```

Despite an extensive internet search I could not find free access to hourly weather data for Newark Airport to supplement the provided data set. 

There are a number of missing values across the weather dataset. 

```{r}
colSums(is.na(newark_weather))
```
All of these variables are numeric. We start by looking at the summary statistics. 

```{r}
newark_weather %>% 
  keep(is.numeric) %>% 
  summary()
```

The following variables have so many missing entries that it makes no sense to impute values for them and they should just be removed from the dataset: `temp`, `dewp`, `humid`, `precip` and `pressure`. 

In addition, `origin` should also be removed as the value for all observations is "EWR", the IATA airport code for Newark Airport. Variables `year`, `month`, `day` and `hour` are already included within `time_hour` so can be safely removed. 

```{r}
newark_weather_clean <- newark_weather %>% 
  select(-c(temp, dewp, humid, precip, pressure)) %>% 
  select(-c(origin, year, month, day, hour))
```

The remaining missing values should be imputed with mean values.

```{r}
newark_weather_clean <- newark_weather_clean %>% 
  mutate(wind_dir = coalesce(wind_dir, mean(wind_dir, na.rm = TRUE)), 
         wind_speed = coalesce(wind_speed, mean(wind_speed, na.rm = TRUE)),
         wind_gust = coalesce(wind_gust, mean(wind_gust, na.rm = TRUE)),
         visib = coalesce(visib, mean(visib, na.rm = TRUE)))
```

The summary statistics should remain relatively unchanged for these variables, which they do.  

```{r}
newark_weather_clean %>% 
  select(wind_dir, wind_speed, wind_gust, visib) %>% 
  summary()
```
There are now no missing values within the newark_weather dataset. 

```{r}
colSums(is.na(newark_weather_clean))
```

For the retained variables there has been no loss of data - there are still 8,735 observations. 

```{r}
dim(newark_weather_clean)
```


_Outliers_
Logistic regression is intolerant to outliers in the data. 

Dealing first with the `newark_flights_clean` dataset. 

```{r, message=FALSE}
newark_flights_clean %>% 
  select(air_time, distance) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```
There is a skew in both the `air_time` and `distance` data within the flights dataset. This can be resolved by removing any value that is larger (right skew) or less than (left skew) 1.5 times the interquartile range (IQR). Quartiles divide an ordered set of values in to four equal parts. The IQR of a set of values is the difference between the values for the first quartile (Q1) and the third quartile (Q3). The value for Q1 is the middle number between the smallest number and the median whilst the Q3 value is the middle number between the median and the highest number. 


```{r}
# remove outliers from flights data
newark_flights_clean <- newark_flights_clean %>% 
  mutate(max_air_time = quantile(air_time, 0.75) + (1.5 * IQR(air_time))) %>% 
  mutate(max_distance = quantile(distance, 0.75) + (1.5 * IQR(distance))) %>% 
  filter(air_time <= max_air_time) %>% 
  filter(distance <= max_distance) %>% 
  select(-c(max_air_time, max_distance))
```

We only lose 716 observations and the range of values for each of these variables is much reduced. 

```{r, message=FALSE}
newark_flights_clean %>% 
  select(air_time, distance) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```

```{r}
glimpse(newark_flights_clean)
```

Next we turn to outliers in the newark weather dataset. 

```{r, message=FALSE}
newark_weather_clean %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```

Wind direction (`wind_dir`) is not skewed so we will retain all of those observations. Visibility (`visib`) has a limited range of values and so will be excluded from quantile reduction. For the `wind_speed` and `wind_gust` we will remove those values more than 1.5 times the IQR (or less than in the case of visibility).

```{r}
# remove outliers from the weather data
newark_weather_clean <- newark_weather_clean %>% 
  mutate(max_wind_gust = quantile(wind_gust, 0.75) + (1.5 * IQR(wind_gust))) %>% 
  mutate(max_wind_speed = quantile(wind_speed, 0.75) + (1.5 * IQR(wind_speed))) %>% 
  filter(wind_gust <= max_wind_gust) %>% 
  filter(wind_speed <= max_wind_speed) %>% 
  select(-c(max_wind_gust, max_wind_speed))
```

We lose 120 observations and the range of values for each of these variables is much reduced. 

```{r, message=FALSE}
newark_weather_clean %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```

_Flight delays and Weather_
We want to examine amongst other things, the impact of weather on delays at Newark Airport, so we should join the cleaned Newark weather data to the cleaned Newark flights data set. 

```{r}
newark_weather_delays <- 
  inner_join(newark_flights_clean, newark_weather_clean, by = "time_hour") %>% 
  select(delayed, wind_dir, wind_speed, wind_gust, visib)
```

The inner join results in a loss of 1,204 observations from the newark_flights_clean dataset of 111,986 or a 1% loss in data. 

_Splitting the dataset_
We want to create a training set of data for our model which we can then test on the remaining data, the test set.

```{r}
# number of rows of data in newark_delays dataset
rows = nrow(newark_weather_delays)

# create a training set
sample_set <- sample(rows, rows * 0.75, replace = FALSE)
weather_delays_train <- newark_weather_delays[sample_set,]

# create a test set
weather_delays_test <- newark_weather_delays[-sample_set,]
```

We want to make sure that the class distribution of the data in the samples mimics that of the original data set. 

```{r}
# class distribution in original dataset
round(prop.table(table(select(newark_weather_delays, delayed), exclude = NULL)), 3) * 100 
```

```{r}
# class distribution in training set
round(prop.table(table(select(weather_delays_train, delayed), exclude = NULL)), 3) * 100 
```

```{r}
# class distribution in test set
round(prop.table(table(select(weather_delays_test, delayed), exclude = NULL)), 3) * 100 
```

There is a slight class imbalance in the training data set. Ideally we would like to have a balanced data set for the model to learn from otherwise it will be skewed towards the dominant class in the data, which in our example is a FALSE (or negative) result for `delayed`. The imbalance is not massively significant so we will continue but make a note for further model development in the future. 

*Training the model*

Let's build the model using the training set of data. 

```{r}
weather_delays_mod1 <- glm(formula = delayed ~ ., data = weather_delays_train, family = binomial(link = "logit"))
```

_Evaluating the model_

```{r}
summary(weather_delays_mod1)
```

The error regarding singularities is most likely due to multicollinearity, or a perfect linear relationship existing between two of the variables. 

We can produce a correlation matrix to see this. 

```{r}
cor(weather_delays_train[, c("wind_dir", "wind_speed", "wind_gust", "visib")])
```
We can see that `wind_speed` and `wind_gust` are perfectly correlated. Let's drop `wind_speed` from the model and re-run it. 

```{r}
weather_delays_mod2 <- glm(formula = delayed ~ wind_dir + wind_gust + visib,
                           family = binomial(link = "logit"),
                           data = weather_delays_train)
```

We can get a detailed description of the model using the summary function.

```{r}
summary(weather_delays_mod2)
```

Of the weather variables, visibility (`visib`) has a very small `p-value` denoted by Pr(>|t|) and is statistically significant (indicated by the 3-stars) as a predictor of flight delays. Also `wind_gust` is statistically signicant at the 5% level. 

The coefficient of each variable is quoted in log-odds. For every unit increase in the value of `visib`, the log-odds of `delayed` being `TRUE` changes by -0.08871. In terms of odds, we have to exponeniate the coefficient as follows:

```{r}
exp(coef(weather_delays_mod2)["visib"])
```

Assuming all other factors are held constant, this value is interpreted as the odds of a flight being delayed decrease by 0.9151078 for each additional mile of visibility gained. 

_Predictive accuracy_
We need to assess the preformance of our model (which is based on training data) in predicting the dependent or response variable for observations in the test data set. 

```{r}
# add predictions to test data set
weather_delays_test_and_pred <- weather_delays_test %>% 
  add_predictions(weather_delays_mod2, type = "response")

# convert predictions to TRUE/FALSE assuming a threshold of 0.5
threshold <- 0.5
weather_delays_test_and_pred <- weather_delays_test_and_pred %>% 
  mutate(pred_thresh_0.5 = pred >= threshold)
```

```{r}
conf_table_weather_delays <- weather_delays_test_and_pred %>% 
  tabyl(delayed, pred_thresh_0.5)

conf_table_weather_delays
```

The correct predictions of the model are top left and bottom right of the table. 

The model correctly predicted "no delay" (`FALSE`) for 16449 observations in the test set and "delay" for 505. That is, True Positives = 16449, whilst True Negatives = 505.

The accuracy of the `weather_delays` model = (16449 + 505) / 27696 = 61%


_Other factors impacting delays_

Having looked at the impact of the weather on flight delays we turn now to consider other factors which may also delay take-off at Newark Airport. 

Returning to the `newark_flights_clean` dataset, we should look to supplement this data by:

- adding data about the plane 
- capturing a measure of 'busy-ness' regarding flights that day or hour
- adding the visibility and wind gust variables from the weather dataset. 

Once complete, we could create another model and assess its predictive quality. 

Let's firstly look at additional information we can glean concerning the planes departing Newark Airport. 

_Planes data_

```{r}
glimpse(plane_data)
```
Of interest are the following variables:

- `tailnum` to link the table to the flights data
- `year` from which we can determine the age of the plane in 2017
- `engines` tells us how many engines the plane has and how many engines could go wrong
- `seats` informs us as to the capacity of the plane and so the potential for passenger caused delays 
- `engine` there are only 8 types of engine which allow us to highlight if there are recurring faults with a particular engine type

Let's clean the plane data of which there are 3,521 observations and 9 variables. 

```{r}
dim(plane_data)
```

Check for missing values. 

```{r}
colSums(is.na(plane_data))
```
Of our variables of interest `year` and `seats` are missing values. We can't impute these values so we should remove the offending observations. We should also remove the `speed` variable as this also has a huge number of missing values. 

```{r}
plane_data_clean <- plane_data %>% 
  select(tailnum, year, engines, seats, engine) %>% 
  drop_na()
```

There should now be no missing values and only 5 variables.

```{r}
colSums(is.na(plane_data_clean))
```

Let's calculate the age of the plane and add this to the dataset.

```{r}
plane_data_clean <- plane_data_clean %>% 
  mutate(age = 2017 - year)
```


Look for outliers in `plane_data_clean`: 

```{r, message=FALSE}
plane_data_clean %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```

There are discrepancies in `age` and `year`.

```{r}
plane_data_clean %>% 
  slice_max(age, n = 5)
```
There is a zero value rather than a missing value in `year`. We need to remove this. 

```{r}
plane_data_clean <- plane_data_clean %>% 
  filter(year != 0)
```

The range of the variables becomes more normal. 

```{r, message=FALSE}
plane_data_clean %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```

We can now remove `year` from `plane_data_clean`.

```{r}
plane_data_clean <- plane_data_clean %>% 
  select(-year)
```


_Measure of busy-ness_
We should look to capture a measure of busy-ness in the flights data. How many flights are taking off that day? That hour?

```{r}
# measures of busy-ness in newark flights data
newark_flights_clean <- newark_flights_clean %>% 
  mutate(date = as.Date(time_hour)) %>% 
  group_by(date) %>% 
  mutate(departures_in_day = n()) %>% 
  ungroup()

newark_flights_clean <- newark_flights_clean %>% 
  group_by(time_hour) %>% 
  mutate(departures_in_hour = n()) %>% 
  ungroup()
```

Check for outliers in new busy-ness variables. 

```{r, message=FALSE}
newark_flights_clean %>% 
  select(departures_in_day, departures_in_hour) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```

`departures_in_day` is skewed left so we should reduce the range of values in this variable. 

```{r}
# remove outliers from departures_in_day
newark_flights_clean <- newark_flights_clean %>% 
  mutate(min_departures_in_day = quantile(departures_in_day, 0.75) - 
           (1.5 * IQR(departures_in_day))) %>% 
  filter(departures_in_day >= min_departures_in_day) %>% 
  select(-c(min_departures_in_day))
```

Outliers have been removed at a cost of 20,475 observations (down from 111,986 to 91,511), about 18% of the dataset. 

```{r, message=FALSE}
newark_flights_clean %>% 
  select(departures_in_day, departures_in_hour) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```

_Flight delays and Other Factors_

Let's combine `newark_flights_clean` with `plane_data_clean` and add in `visib` from `newark_weather_clean`. We can then build another model to examine the impact of 'other factors' on delays at Newark Airport. 

```{r}
newark_other_delays <- 
  inner_join(newark_flights_clean, plane_data_clean, by = "tailnum") %>% 
  select(-date, -tailnum) # remove unwanted variables
```

We lose 7,802 observations with the inner join on the plane data, down to 83,709.

Combine this with `visib` and `wind_gust` from the weather data. 

```{r}
newark_other_delays <-
  inner_join(newark_other_delays, newark_weather_clean, by = "time_hour") %>% 
  select(-c(wind_dir, wind_speed, time_hour)) # remove unwanted weather variables 
```

We lose another 750 observations, down to 82959.


_Splitting the dataset_
Again, we want to create a training set of data for our model which we can then test on the remaining data, the test set.

```{r}
# number of rows of data in newark_other_delays dataset
rows = nrow(newark_other_delays)

# create a training set
sample_set <- sample(rows, rows * 0.75, replace = FALSE)
other_delays_train <- newark_other_delays[sample_set,]

# create a test set
other_delays_test <- newark_other_delays[-sample_set,]
```

We want to make sure that the class distribution of the data in the samples mimics that of the original data set. 

```{r}
# class distribution in original dataset
round(prop.table(table(select(newark_other_delays, delayed), exclude = NULL)), 3) * 100 
```

```{r}
# class distribution in training set
round(prop.table(table(select(other_delays_train, delayed), exclude = NULL)), 3) * 100 
```

```{r}
# class distribution in test set
round(prop.table(table(select(other_delays_test, delayed), exclude = NULL)), 3) * 100 
```

Again there is a slight class imbalance in the training data set. The imbalance is not massively significant so we will continue but make a note for further model development in the future. 


*Training the model*

Let's build the model using the training set of data. 

```{r}
other_delays_mod1 <- glm(formula = delayed ~ ., data = other_delays_train, family = binomial(link = "logit"))
```

_Evaluating the model_

```{r}
summary(other_delays_mod1)
```
_Improving the model_

The `NAs` returned for `distance` indicate that multicollinearity exists in the model. That is, two or more predictor variables are highly (or perfectly) correlated. We can generate a correlation matrix to see the inter-relationship of the numerical variables. In this instance it is likely that there is a high correlation between `distance` and `air_time`.

```{r}
other_delays_train %>% 
  select(air_time, distance) %>% 
  cor()
```

The correlation between the two variables is very strong (0.99). We should remove one of them from the model. 

Whilst the correlation matrix can be used for numerical variables we must also consider if there are any aliased variables in the model. Again, this is another measure of correlation between variables.  

```{r}
alias(other_delays_mod1)
```

It's clear that `distance` and `dest` are also highly correlated, which makes sense. 

Let's remove `air_time` and `dest` but retain `distance` which is a more intuitive and accurate measure of length or duration, and rebuild the model. 

```{r}
other_delays_mod2 <- glm(formula = delayed ~ carrier + distance + hour + day +
                           departures_in_day + departures_in_hour + engines + seats +
                           engine + age + wind_gust + visib, 
                         data = other_delays_train, family = binomial(link = "logit"))
```

```{r}
summary(other_delays_mod2)
```
We can test the collinearity of variables in the model using the `vif` function from the `car` package.

```{r}
vif(other_delays_mod2)
```
VIF stands for variance inflation factor and is useful to identify correlation where it may exist between three or more variables rather than just between pairs. 

A VIF of 5 or more indicates the presence of multicollinearity. We can see that `carrier` and `engine` both have values in excess of 5 and should be removed from the model. 

Reviewing the summary statistics of the model shows that `hour`, `day`, `departures_in_day`, `departures_in_hour`, `seats`, `age`, `wind_gust` and `visib` are statistically significant predictor variables. Whilst `carrier` is significant it fails the VIF test and is removed. 

```{r}
other_delays_mod3 <- glm(formula = delayed ~ hour + day + departures_in_day +
                           departures_in_hour + seats + age + wind_gust + visib, 
                         data = other_delays_train, family = binomial(link = "logit"))
```

```{r}
summary(other_delays_mod3)
```

We note that `age` is not statistically significant, so another iteration of the model is required to remove this predictor variable. 

```{r}
other_delays_mod4 <- glm(formula = delayed ~ hour + day + departures_in_day +
                           departures_in_hour + seats + wind_gust + visib, 
                         data = other_delays_train, family = binomial(link = "logit"))
```

```{r}
summary(other_delays_mod4)
```

_Predictive accuracy_
We need to assess the preformance of our model (which is based on training data) in predicting the dependent or response variable for observations in the test data set. 

```{r}
# add predictions to test data set
other_delays_test_and_pred <- other_delays_test %>% 
  add_predictions(other_delays_mod4, type = "response")

# convert predictions to TRUE/FALSE assuming a threshold of 0.5
threshold <- 0.5
other_delays_test_and_pred <- other_delays_test_and_pred %>% 
  mutate(pred_thresh_0.5 = pred >= threshold)
```

```{r}
conf_table_other_delays <- other_delays_test_and_pred %>% 
  tabyl(delayed, pred_thresh_0.5)

conf_table_other_delays
```

The correct predictions of the model are top left and bottom right of the table. 

The model correctly predicted "no delay" (`FALSE`) for 9830 observations in the test set and "delay" for 4090 That is, True Positives = 9830, whilst True Negatives = 4090.

The accuracy of the `weather_delays` model = (9830 + 4090) / 20740 = 67%


*Cancelled flights model*

As noted earlier there appears to be a number of cancelled flights in the `flights` dataset denoted by `NA` values within the `air_time` variable.

```{r}
newark_cancelled <- newark_flights

colSums(is.na(newark_cancelled))
```
There would appear to be 3,266 cancelled flights. 

Let's create a logistic regression model to see how well we can predict cancellations from the given data. 

Firstly, we need to remove `dep_delay` as this is irrelevant to flight cancellations - a flight can't be recorded as delayed and cancelled. 

```{r}
newark_cancelled_clean <- newark_cancelled %>% 
  select(-dep_delay)
```

Again, I'll replace the missing values within `tailnum` with "ABCXYZ".

```{r}
newark_cancelled_clean <- newark_cancelled_clean %>% 
  mutate(tailnum = ifelse(is.na(tailnum), "ABCXYZ", tailnum))
```

The only missing values in the dataset should now relate to `air_time`. 

```{r}
colSums(is.na(newark_cancelled_clean))
```

Let's create a new variable (`cancelled`) by converting the values within `air_time` to either TRUE (`NA`) or FALSE, then remove the `air_time` variable.

```{r}
newark_cancelled_clean <- newark_cancelled_clean %>% 
  mutate(cancelled = ifelse(is.na(air_time), TRUE, FALSE)) %>% 
  select(-air_time) 
```

We should add a measure of busy-ness to the cancelled flights data. 

```{r}
# measures of busy-ness in newark flights data
newark_cancelled_clean <- newark_cancelled_clean %>% 
  mutate(date = as.Date(time_hour)) %>% 
  group_by(date) %>% 
  mutate(departures_in_day = n()) %>% 
  ungroup()

newark_cancelled_clean <- newark_cancelled_clean %>% 
  group_by(time_hour) %>% 
  mutate(departures_in_hour = n()) %>% 
  ungroup()
```


_Outliers_

Logistic regression is intolerant to outliers in the data so let's remove them from the `cancelled_flights` dataset. 

```{r}
# remove outliers from cancelled flights data
newark_cancelled_clean <- newark_cancelled_clean %>% 
  mutate(max_distance = quantile(distance, 0.75) + (1.5 * IQR(distance))) %>% 
  mutate(min_departures_in_day = quantile(departures_in_day, 0.75) - 
           (1.5 * IQR(departures_in_day))) %>% 
  filter(distance <= max_distance) %>% 
  filter(departures_in_day >= min_departures_in_day) %>% 
  select(-c(max_distance, min_departures_in_day))
```


_Join cancelled dataset to weather and plane data_

We want to join the cleaned weather and plane datasets to the clean cancelled flights data. 

```{r}
newark_cancelled_weather <- 
  inner_join(newark_cancelled_clean, newark_weather_clean, by = "time_hour") %>% 
  select(-date, -time_hour) # remove unwanted variables

newark_cancelled_weather_other <- 
  inner_join(newark_cancelled_weather, plane_data_clean, by = "tailnum") %>% 
  select(-tailnum) # remove unwanted variables
```


_Splitting the dataset_
Again, we want to create a training set of data for our model which we can then test on the remaining data, the test set. First let's examine the class imbalance in the full dataset.

```{r}
# class distribution in original dataset
round(prop.table(table(select(newark_cancelled_weather_other, cancelled), exclude = NULL)), 3) * 100 
```

It is highly imbalanced. This needs correcting before we proceed to building a model. 

To correct the imbalance, the `ROSE` package (Random Over-Sampling Examples) requires that variables are either categorical (`as.factor`) or continuous numeric. To achieve this variables with `chr` data types need to be removed and all other variables converted to either `dbl` or `fct`.

```{r}
newark_cancelled_weather_other_ROSE <- newark_cancelled_weather_other %>% 
  mutate(month = as.numeric(month),
         day = case_when(
           day == "Mon" ~ 1, 
           day == "Tue" ~ 2, 
           day == "Wed" ~ 3, 
           day == "Thu" ~ 4,
           day == "Fri" ~ 5,
           day == "Sat" ~ 6,
           day == "Sun" ~ 7
         ),
         cancelled = as.factor(cancelled),
         departures_in_day = as.numeric(departures_in_day),
         departures_in_hour = as.numeric(departures_in_hour)
         ) %>% 
  select(-c(carrier, dest, engine))
```

We then need to split this ROSE compatible dataset into a training and test set of data.  

```{r}
# number of rows of data in newark_cancelled_weather_other dataset
rows = nrow(newark_cancelled_weather_other_ROSE)

# create a training set
sample_set <- sample(rows, rows * 0.75, replace = FALSE)
cancelled_train <- newark_cancelled_weather_other_ROSE[sample_set,]

# create a test set
cancelled_test <- newark_cancelled_weather_other_ROSE[-sample_set,]
```


Again the class distribution of the original data set is as follows: 

```{r}
# class distribution in original dataset
round(prop.table(table(select(newark_cancelled_weather_other_ROSE, cancelled), exclude = NULL)), 3) * 100 
```

The class distribution of the training set will reflect this. 

```{r}
# class distribution in training set
round(prop.table(table(select(cancelled_train, cancelled), exclude = NULL)), 3) * 100 
```

Let's use the ROSE package to over-sample the minority class (`TRUE`) and balance the training set. 

```{r}
cancelled_train_ROSE <- ROSE(cancelled ~., data = cancelled_train, seed = 1)$data
# class distribution in training set
round(prop.table(table(select(cancelled_train_ROSE, cancelled), exclude = NULL)), 3) * 100 
```

This is now a well balanced training data set. 

The test set will still reflect the make-up of the original dataset. 

```{r}
# class distribution in test set
round(prop.table(table(select(cancelled_test, cancelled), exclude = NULL)), 3) * 100 
```


*Training the model*

Let's build the model using the training set of data. 

```{r}
cancelled_flights_mod1 <- glm(formula = cancelled ~ ., data = cancelled_train_ROSE, family = binomial(link = "logit"))
```

_Evaluating the model_

```{r}
summary(cancelled_flights_mod1)
```

All of the variables are statistically significant. 

Let's test the collinearity of variables in the model using the `vif` function from the `car` package.

```{r}
vif(cancelled_flights_mod1)
```

There doesn't appear to be significant multicollinearity in the model as no VIF values are above 5.


_Predictive accuracy_
We need to assess the preformance of our model (which is based on training data) in predicting the dependent or response variable for observations in the test data set. 

```{r}
# add predictions to test data set
cancelled_flights_test_and_pred <- cancelled_test %>% 
  add_predictions(cancelled_flights_mod1, type = "response")

# convert predictions to TRUE/FALSE assuming a threshold of 0.5
threshold <- 0.5
cancelled_flights_test_and_pred <- cancelled_flights_test_and_pred %>% 
  mutate(pred_thresh_0.5 = pred >= threshold)
```

```{r}
conf_table_cancelled_flights <- cancelled_flights_test_and_pred %>% 
  tabyl(cancelled, pred_thresh_0.5)

conf_table_cancelled_flights
```

The correct predictions of the model are top left and bottom right of the table. 

The model correctly predicted "no delay" (`FALSE`) for 13,762 observations in the test set and "delay" for 365 That is, True Positives = 13,762, whilst True Negatives = 365

The accuracy of the `cancelled_flights` model = (13,762 + 365) / 21,808 = 64%






































