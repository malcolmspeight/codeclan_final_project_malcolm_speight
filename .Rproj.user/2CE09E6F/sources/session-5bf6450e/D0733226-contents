---
title: "Newark Flight Data"
author: "Malcolm Speight"
date: "2023-02-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
```

```{r, include=FALSE}
flights_data <- read_csv("data/flights.csv") %>% 
  janitor::clean_names()
airports_data <- read_csv("data/airports.csv") %>% 
  janitor::clean_names()
weather_data <- read_csv("data/weather.csv") %>% 
  janitor::clean_names()
plane_data <- read_csv("data/planes.csv") %>% 
  janitor::clean_names()
```


*Logistic regression*

Attempting to define a linear regression model for delays and weather data proved inconclusive. Linear regression is suited to addressing dependent variables that have continuous values. However, the delay associated with a plane departing an airport can be seen not to have a linear relationship to a series of variables as their impact on delay is changeable and dependent on many other factors or a combination of factors. In such circumstances it is clearly better to categorise our dependent variable, to begin with at least, as having two values: `delay` or `no-delay`.  

**Weather related delays**

_Flight data_
Flights leaving Newark Airport can be extracted from the main flights dataset (`flights_data`) after joining with `airports_data` and filtering on Newark Airport. 

```{r}
# capture only newark airport flights
newark_flights <- inner_join(flights_data, airports_data, by = c("origin" = "faa")) %>% 
  filter(name == "Newark Liberty International Airport") 
```

The `newark_flights` data contains 26 variables with 115,968 observations. 

```{r}
glimpse(newark_flights)
```

Some of the data is superfluous and is repeated for each entry so we can remove details of Newark Airport such as the `name` and `latitude` and `longitude` and the like. 

```{r}
newark_flights <- newark_flights %>% 
  select(-c(name, lat, lon, alt, tz, dst, tzone, origin))
```

There are a number of missing values across the dataset. 

```{r}
colSums(is.na(newark_flights))
```
Of these only `tailnum` is a character data type. All the other are numeric. Dealing with the numeric first, we start by looking at the summary statistics. 

```{r}
newark_flights %>% 
  keep(is.numeric) %>% 
  summary()
```
For `dep_time`, `dep_delay`, `arr_time`, `arr_delay` we can use mean imputation to resolve the missing values. 

```{r}
newark_flights_clean <- newark_flights %>% 
  mutate(dep_time = coalesce(dep_time, mean(dep_time, na.rm = TRUE)), 
         dep_delay = coalesce(dep_delay, mean(dep_delay, na.rm = TRUE)), 
         arr_time = coalesce(arr_time, mean(arr_time, na.rm = TRUE)), 
         arr_delay = coalesce(arr_delay, mean(arr_delay, na.rm = TRUE)))
```

The summary statistics should for these variables should remain similar to that prior to adjustment, as is the case here.  

```{r}
newark_flights_clean %>% 
  select(dep_time, dep_delay, arr_time, arr_delay) %>% 
  summary()
```
The remaining numerical variable, `air_time` has a considerable number of missing values. These could be considered erroneous but more likely they indicate that the flight has been cancelled. A new variable (`cancelled`) should be added to capture this information then the `NA` values within `air_time` can be converted to a zero value. 

```{r}
newark_flights_clean <- newark_flights_clean %>% 
  mutate(cancelled_flight = ifelse(is.na(air_time), TRUE, FALSE), .after = air_time) %>% 
  mutate(air_time = coalesce(air_time, 0))
```

The summary statistics are relatively unchanged for air_time whilst the number of `cancelled_flight` TRUE observations matches the previous number of `NA` values within `air_time`

```{r}
newark_flights_clean %>% 
  select(cancelled_flight, air_time) %>% 
  summary()
```
For the remaining `tailnum` variable, I'll replace missing values with "ABCXYZ".

```{r}
newark_flights_clean <- newark_flights_clean %>% 
  mutate(tailnum = ifelse(is.na(tailnum), "ABCXYZ", tailnum))
```

There should now be no missing values within the newark_flights_clean dataset with the loss of no data. 

```{r}
colSums(is.na(newark_flights_clean))
```

And there are still 115,968 observations and we have added a `cancelled_flight` variable.

```{r}
dim(newark_flights_clean)
```

_Dependent variable_
There is currently no dependent variable (class) in the dataset so we should add one. Newark Airport are interested in departure delays. Although the US aviation authority (The FAA) state that flights departing with less than a 15 minute delay are deemed to be 'on time', we will classify all flights with a departure delay of greater than 0 as being delayed. 

```{r}
# add dependent variable
newark_flights_clean <- newark_flights_clean %>% 
  mutate(delayed = ifelse(dep_delay > 0, TRUE, FALSE), .after = dep_delay)
```


_Weather data_
Weather relating to Newark Airport can be extracted from the larger `weather_data` population by filtering on "EWR", the IATA code for Newark Airport.

```{r}
# capture only newark weather
newark_weather <- weather_data %>% 
  filter(origin == "EWR")
```

The newark weather data contains 15 variables with 8,735 observations. 

```{r}
glimpse(newark_weather)
```

Despite an extensive internet search I could not find free access to hourly weather data for Newark Airport to supplement the provided data set. 

There are a number of missing values across the weather dataset. 

```{r}
colSums(is.na(newark_weather))
```
All of these variables are numeric. We start by looking at the summary statistics. 

```{r}
newark_weather %>% 
  keep(is.numeric) %>% 
  summary()
```

The following variables have so many missing entries that it makes no sense to impute values for them and they should just be removed from the dataset: `temp`, `dewp`, `humid`, `precip` and `pressure`. 

In addition, `origin` should also be removed as the value for all observations is "EWR", the IATA airport code for Newark Airport. Variables `year`, `month`, `day` and `hour` are already included within `time_hour` so can be safely removed. 

```{r}
newark_weather_clean <- newark_weather %>% 
  select(-c(temp, dewp, humid, precip, pressure)) %>% 
  select(-c(origin, year, month, day, hour))
```

The remaining missing values should be imputed with mean values.

```{r}
newark_weather_clean <- newark_weather_clean %>% 
  mutate(wind_dir = coalesce(wind_dir, mean(wind_dir, na.rm = TRUE)), 
         wind_speed = coalesce(wind_speed, mean(wind_speed, na.rm = TRUE)),
         wind_gust = coalesce(wind_gust, mean(wind_gust, na.rm = TRUE)),
         visib = coalesce(visib, mean(visib, na.rm = TRUE)))
```

The summary statistics should remain relatively unchanged for these variables, which they do.  

```{r}
newark_weather_clean %>% 
  select(wind_dir, wind_speed, wind_gust, visib) %>% 
  summary()
```
There are now no missing values within the newark_weather dataset. 

```{r}
colSums(is.na(newark_weather_clean))
```
For the retained variables there has been no loss of data - there are still 8,735 observations. 

```{r}
dim(newark_weather_clean)
```

_Flight delays_
We want to examine amongst other things, the impact of weather on delays at Newark Airport, so we should join the cleaned Newark weather data to the clean flights data set. 

```{r}
newark_delays <- 
  inner_join(newark_flights_clean, newark_weather_clean, by = "time_hour")
```

The inner join results in a loss of 275 observations from the original newark_flights dataset of 115,968 or a 0.2% loss in data. 

_Splitting the dataset_
We want to create a training set of data for our model which we can then test on the remaining data, the test set.

```{r}
# number of rows of data in newark_delays dataset
rows = nrow(newark_delays)

# create a training set
sample_set <- sample(rows, rows * 0.75, replace = FALSE)
delays_train <- newark_delays[sample_set,]

# create a test set
delays_test <- newark_delays[-sample_set,]
```

We want to make sure that the class distribution of the data in the samples mimics that of the original data set. 

```{r}
# class distribution in original dataset
round(prop.table(table(select(newark_delays, delayed), exclude = NULL)), 3) * 100 
```

```{r}
# class distribtion in training set
round(prop.table(table(select(delays_train, delayed), exclude = NULL)), 3) * 100 
```

```{r}
# class distribtion in test set
round(prop.table(table(select(delays_test, delayed), exclude = NULL)), 3) * 100 
```

There is a slight class imbalance in the training data set. Ideally we would like to have a balanced data set for the model to learn from otherwise it will be skewed towards the dominant class in the data, which in our example is a FALSE (or negative) result for `delay`. The imbalance is not massively significant so we will continue but make a note for further model development in the future. 

*Training the model*

Let's build the model using the training set of data. 

```{r}
delays_mod1 <- glm(formula = delayed ~ ., data = delays_train, family = binomial(link = "logit"))
```































