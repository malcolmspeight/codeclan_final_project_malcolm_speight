---
title: "Newark Flight Data"
author: "Malcolm Speight"
date: "2023-02-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(modelr)
library(janitor)
```

```{r, include=FALSE}
flights_data <- read_csv("data/flights.csv") %>% 
  janitor::clean_names()
airports_data <- read_csv("data/airports.csv") %>% 
  janitor::clean_names()
weather_data <- read_csv("data/weather.csv") %>% 
  janitor::clean_names()
plane_data <- read_csv("data/planes.csv") %>% 
  janitor::clean_names()
```


*Logistic regression*

Attempting to define a linear regression model for delays and weather data proved inconclusive. Linear regression is suited to addressing dependent variables that have continuous values. However, the delay associated with a plane departing an airport can be seen not to have a linear relationship to a series of variables as their impact on delay is changeable and dependent on many other factors or a combination of factors. In such circumstances it is clearly better to categorise our dependent variable, to begin with at least, as having two values: `delay` or `no-delay`.  

**Weather related delays**

_Flight data_
Flights leaving Newark Airport can be extracted from the main flights dataset (`flights_data`) after joining with `airports_data` and filtering on Newark Airport. 

```{r}
# capture only newark airport flights
newark_flights <- inner_join(flights_data, airports_data, by = c("origin" = "faa")) %>% 
  filter(name == "Newark Liberty International Airport") 
```

The `newark_flights` data contains 26 variables with 115,968 observations. 

```{r}
glimpse(newark_flights)
```

Some of the data is superfluous and is repeated for each entry so we can remove details of Newark Airport such as the `name` and `latitude` and `longitude` and the like. Also `year`, `month`, `day` are already captured within `time_hour` so can be removed. Also captured by `time_hour` are `dep_time`, `sched_dep_time` and `hour`. The `minute` variable is superfluous. The arrival times, both scheduled and actual, and arrival delay are not predictor variables as they are a consequence of any delay so can be removed also. 

```{r}
newark_flights <- newark_flights %>% 
  select(-c(name, lat, lon, alt, tz, dst, tzone, origin)) %>% 
  select(-c(year, month, day, hour, minute)) %>% 
  select(-c(dep_time, sched_dep_time, arr_time, sched_arr_time, arr_delay))
```

We reduce the number of variables from 26 to 8.

```{r}
glimpse(newark_flights)
```

There are a number of missing values across the dataset. 

```{r}
colSums(is.na(newark_flights))
```

We start by looking at the summary statistics. 

```{r}
newark_flights %>% 
  select(dep_delay, tailnum, air_time) %>% 
  summary()
```
The amount of time the flight spends in the air (`air_time`) has a considerable number of missing values. These could be considered erroneous but more likely they indicate that the flight has been cancelled. A new variable (`cancelled`) could be added to capture this information then the `NA` values within `air_time` can be converted to a zero value. This would allow another regression model to be constructed to predict cancellations. For the moment, we will remove the `NA` values within `air_time`.

```{r}
# remove NAs from air_time
newark_flights_clean <- newark_flights %>% 
  drop_na(air_time)
```

For `dep_delay` we can use mean imputation to resolve the missing values. 

```{r}
newark_flights_clean <- newark_flights_clean %>% 
  mutate(dep_delay = coalesce(dep_delay, mean(dep_delay, na.rm = TRUE)))
```

The summary statistics are relatively unchanged for `dep_delay` 

```{r}
newark_flights_clean %>% 
  select(dep_delay) %>% 
  summary()
```
For the remaining `tailnum` variable, I'll replace missing values with "ABCXYZ".

```{r}
newark_flights_clean <- newark_flights_clean %>% 
  mutate(tailnum = ifelse(is.na(tailnum), "ABCXYZ", tailnum))
```

There should now be no missing values within the newark_flights_clean dataset. 

```{r}
colSums(is.na(newark_flights_clean))
```


The number of observations has reduced by the number of `NAs` or cancelled flights (3,266) captured within `air_time`. We now have 112,702 observations.

```{r}
dim(newark_flights_clean)
```


_Dependent variable_
There is currently no dependent variable (class) in the dataset so we should add one. Newark Airport are interested in departure delays. Although the US aviation authority (The FAA) state that flights departing with less than a 15 minute delay are deemed to be 'on time', we will classify all flights with a departure delay of greater than 0 as being delayed. Once added we can remove the `dep_delay` variable.

```{r}
# add dependent variable
newark_flights_clean <- newark_flights_clean %>% 
  mutate(delayed = ifelse(dep_delay > 0, TRUE, FALSE), .after = dep_delay) %>% 
  select(-dep_delay)
```


_Weather data_
Weather relating to Newark Airport can be extracted from the larger `weather_data` population by filtering on "EWR", the IATA code for Newark Airport.

```{r}
# capture only newark weather
newark_weather <- weather_data %>% 
  filter(origin == "EWR")
```

The newark weather data contains 15 variables with 8,735 observations. 

```{r}
glimpse(newark_weather)
```

Despite an extensive internet search I could not find free access to hourly weather data for Newark Airport to supplement the provided data set. 

There are a number of missing values across the weather dataset. 

```{r}
colSums(is.na(newark_weather))
```
All of these variables are numeric. We start by looking at the summary statistics. 

```{r}
newark_weather %>% 
  keep(is.numeric) %>% 
  summary()
```

The following variables have so many missing entries that it makes no sense to impute values for them and they should just be removed from the dataset: `temp`, `dewp`, `humid`, `precip` and `pressure`. 

In addition, `origin` should also be removed as the value for all observations is "EWR", the IATA airport code for Newark Airport. Variables `year`, `month`, `day` and `hour` are already included within `time_hour` so can be safely removed. 

```{r}
newark_weather_clean <- newark_weather %>% 
  select(-c(temp, dewp, humid, precip, pressure)) %>% 
  select(-c(origin, year, month, day, hour))
```

The remaining missing values should be imputed with mean values.

```{r}
newark_weather_clean <- newark_weather_clean %>% 
  mutate(wind_dir = coalesce(wind_dir, mean(wind_dir, na.rm = TRUE)), 
         wind_speed = coalesce(wind_speed, mean(wind_speed, na.rm = TRUE)),
         wind_gust = coalesce(wind_gust, mean(wind_gust, na.rm = TRUE)),
         visib = coalesce(visib, mean(visib, na.rm = TRUE)))
```

The summary statistics should remain relatively unchanged for these variables, which they do.  

```{r}
newark_weather_clean %>% 
  select(wind_dir, wind_speed, wind_gust, visib) %>% 
  summary()
```
There are now no missing values within the newark_weather dataset. 

```{r}
colSums(is.na(newark_weather_clean))
```
For the retained variables there has been no loss of data - there are still 8,735 observations. 

```{r}
dim(newark_weather_clean)
```


_Outliers_
Logistic regression is intolerant to outliers in the data. 

Dealing first with the `newark_flights_clean` dataset. 

```{r, message=FALSE}
newark_flights_clean %>% 
  select(air_time, distance) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```
There is a skew in all the numerical data within the flights dataset. This can be resolved by removing any value that is larger (right skew) or less than (left skew) 1.5 times the interquartile range (IQR). Quartiles divide an ordered set of values in to four equal parts. The IQR of a set of values is the difference between the values for the first quartile (Q1) and the third quartile (Q3). The value for Q1 is the middle number between the smallest number and the median whilst the Q3 value is the middle number between the median and the highest number. 


```{r}
# remove outliers from flights data
newark_flights_clean <- newark_flights_clean %>% 
  mutate(max_air_time = quantile(air_time, 0.75) + (1.5 * IQR(air_time))) %>% 
  mutate(max_distance = quantile(distance, 0.75) + (1.5 * IQR(distance))) %>% 
  filter(air_time <= max_air_time) %>% 
  filter(distance <= max_distance) %>% 
  select(-c(max_air_time, max_distance))
```

We only lose 685 observations and the range of values for each of these variables is much reduced. 

```{r, message=FALSE}
newark_flights_clean %>% 
  select(air_time, distance) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```

```{r}
glimpse(newark_flights_clean)
```

Next we turn to outliers in the newark weather dataset. 

```{r, message=FALSE}
newark_weather_clean %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```
Wind direction (`wind_dir`) is not skewed so we will retain all of those observations. Visibility (`visib`) has a limited range of values and so will be excluded from quantile reduction. For the remainder we will remove those values more than 1.5 times the IQR (or less than in the case of visibility).

```{r}
# remove outliers from the weather data
newark_weather_clean <- newark_weather_clean %>% 
  mutate(max_wind_gust = quantile(wind_gust, 0.75) + (1.5 * IQR(wind_gust))) %>% 
  mutate(max_wind_speed = quantile(wind_speed, 0.75) + (1.5 * IQR(wind_speed))) %>% 
  filter(wind_gust <= max_wind_gust) %>% 
  filter(wind_speed <= max_wind_speed) %>% 
  select(-c(max_wind_gust, max_wind_speed))
```

We lose 120 observations and the range of values for each of these variables is much reduced. 

```{r, message=FALSE}
newark_weather_clean %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = key), colour = "black") +
  facet_wrap(~ key, scales = "free") + 
  theme_minimal()
```

_Flight delays_
We want to examine amongst other things, the impact of weather on delays at Newark Airport, so we should join the cleaned Newark weather data to the clean flights data set. 

```{r}
newark_weather_delays <- 
  inner_join(newark_flights_clean, newark_weather_clean, by = "time_hour") %>% 
  select(delayed, wind_dir, wind_speed, wind_gust, visib)
```

The inner join results in a loss of 5,186 observations from the original newark_flights dataset of 115,968 or a 1% loss in data. 

_Splitting the dataset_
We want to create a training set of data for our model which we can then test on the remaining data, the test set.

```{r}
# number of rows of data in newark_delays dataset
rows = nrow(newark_weather_delays)

# create a training set
sample_set <- sample(rows, rows * 0.75, replace = FALSE)
weather_delays_train <- newark_weather_delays[sample_set,]

# create a test set
weather_delays_test <- newark_weather_delays[-sample_set,]
```

We want to make sure that the class distribution of the data in the samples mimics that of the original data set. 

```{r}
# class distribution in original dataset
round(prop.table(table(select(newark_weather_delays, delayed), exclude = NULL)), 3) * 100 
```

```{r}
# class distribtion in training set
round(prop.table(table(select(weather_delays_train, delayed), exclude = NULL)), 3) * 100 
```

```{r}
# class distribution in test set
round(prop.table(table(select(weather_delays_test, delayed), exclude = NULL)), 3) * 100 
```

There is a slight class imbalance in the training data set. Ideally we would like to have a balanced data set for the model to learn from otherwise it will be skewed towards the dominant class in the data, which in our example is a FALSE (or negative) result for `delayed`. The imbalance is not massively significant so we will continue but make a note for further model development in the future. 

*Training the model*

Let's build the model using the training set of data. 

```{r}
weather_delays_mod1 <- glm(formula = delayed ~ ., data = weather_delays_train, family = binomial(link = "logit"))
```

_Evaluating the model_

```{r}
summary(weather_delays_mod1)
```

The error regarding singularities is most likely due to multicollinearity, or a perfect linear relationship existing between two of the variables. 

We can produce a correlation matrix to see this. 

```{r}
cor(weather_delays_train[, c("wind_dir", "wind_speed", "wind_gust", "visib")])
```
We can see that `wind_speed` and `wind_gust` are perfectly correlated. Let's drop `wind_speed` from the model and re-run it. 

```{r}
weather_delays_mod2 <- glm(formula = delayed ~ wind_dir + wind_gust + visib,
                           family = binomial(link = "logit"),
                           data = weather_delays_train)
```

We can get a detailed description of the model using the summary function.

```{r}
summary(weather_delays_mod2)
```

Of the weather variables, only visibility (`visib`) has a very small `p-value` denoted by Pr(>|t|) and is statistically significant (indicated by the 3-stars) as a predictor of flight delays. 

The coefficient of `visib` is quoted in log-odds. For every unit increase in the value of `visib`, the log-odds of `delayed` being `TRUE` changes by -0.08964. In terms of odds, we have to exponeniate the coefficient as follows:

```{r}
exp(coef(weather_delays_mod2)["visib"])
```

Assuming all other factors are held constant, this value is interpreted as the odds of a flight being delayed decrease by 0.9142625 for each additional mile of visibility gained. 

_Predictive accuracy_
We need to assess the preformance of our model (which is based on training data) in predicting the dependent or response variable for observations in the test data set. 

```{r}
# add predictions to test data set
weather_delays_test_and_pred <- weather_delays_test %>% 
  add_predictions(weather_delays_mod2, type = "response")

# convert predictions to TRUE/FALSE assuming a threshold of 0.5
threshold <- 0.5
weather_delays_test_and_pred <- weather_delays_test_and_pred %>% 
  mutate(pred_thresh_0.5 = pred >= threshold)

head(weather_delays_test_and_pred)
```

```{r}
conf_table_weather_delays <- weather_delays_test_and_pred %>% 
  tabyl(delayed, pred_thresh_0.5)

conf_table_weather_delays
```

The correct predictions of the model are top left and bottom right of the table. 

The model correctly predicted "no delay" (`FALSE`) for 16397 observations in the test set and "delay" for 567. That is, True Positives = 16397, whilst True Negatives = 567.

The accuracy of the `weather_delays` model = (16397 + 567) / 27696 = 61.25%



















